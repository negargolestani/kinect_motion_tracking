{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import*\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################################\n",
    "class NODE(object):\n",
    "    ################################################################################################################################################\n",
    "    def __init__(self, markers_color, IDD=None, port=None):\n",
    "        self.markers_color = markers_color\n",
    "        self.IDD = IDD\n",
    "        self.port = port\n",
    "    ################################################################################################################################################\n",
    "    def get_data(self, dataset_name, file_name, ref_node=None, window_length=11, ref_node_data=None, full_motion_data=False):        \n",
    "        \n",
    "        data = self.get_motion(dataset_name, file_name, window_length=window_length, ref_node_data=ref_node_data, full_motion_data=full_motion_data)  \n",
    "        time = data.time    # use kinect time as ref time\n",
    "\n",
    "        if self.IDD is not None: \n",
    "            rssi = self.get_rssi(dataset_name, file_name, window_length=window_length)\n",
    "            data = data.merge( rssi, on='time', how='outer', suffixes=('', ''), sort=True)            \n",
    "            # t_start, t_end = max(t_start, rssi.time.iloc[0]), min(t_end,  rssi.time.iloc[-1])\n",
    "            time = time.loc[time> rssi.time.iloc[0]].loc[time< rssi.time.iloc[-1]]\n",
    "\n",
    "        if self.port is not None: \n",
    "            vind = self.get_vind(dataset_name, file_name, window_length=window_length)\n",
    "            data = data.merge( vind, on='time', how='outer', suffixes=('', ''), sort=True)\n",
    "            # t_start, t_end = max(t_start, vind.time.iloc[0]), min(t_end,  vind.time.iloc[-1])\n",
    "            time = time.loc[time> vind.time.iloc[0]].loc[time< vind.time.iloc[-1]]\n",
    "        \n",
    "        data.interpolate(method='nearest', axis=0, inplace=True)      \n",
    "        data = pd.merge( pd.DataFrame(time), data, on='time', how='inner', suffixes=('', ''), sort=True)\n",
    "\n",
    "        return data\n",
    "    ################################################################################################################################################\n",
    "    def get_motion(self, dataset_name, file_name, window_length=11, ref_node_data=None, full_motion_data=False):   \n",
    "        markers_file_path = get_markers_file_path(dataset_name, file_name)  \n",
    "        raw_df  = pd.read_csv(\n",
    "            markers_file_path,                                                  # relative python path to subdirectory\n",
    "            usecols = ['time', self.markers_color],                             # Only load the three columns specified.\n",
    "            parse_dates = ['time'] )         \n",
    "\n",
    "        # Time\n",
    "        date_time = pd.to_datetime( raw_df['time'] , format=datime_format)\n",
    "        time = [ np.round( (datetime.combine(date.min, t.time())-datetime.min).total_seconds(), 2) for t in date_time]\n",
    "        \n",
    "        # Markers\n",
    "        markers = [list(map(float, l.replace(']','').replace('[','').replace('\\n','').split(\", \"))) for l in raw_df[self.markers_color].values]  \n",
    "        markers_npy = np.array(markers).reshape(len(time), -1, 3)\n",
    "        # DON'T Smooth markers. markers can be switched in array and smoothing causes error    \n",
    "\n",
    "        # Center    \n",
    "        center = np.mean(markers_npy, axis=1)         \n",
    "        center = np.nan_to_num(center)\n",
    "        center = signal.savgol_filter( center, window_length=window_length, polyorder=1, axis=0)     \n",
    "\n",
    "        # Norm\n",
    "        norm = np.cross( markers_npy[:,1,:] - markers_npy[:,0,:], markers_npy[:,2,:] - markers_npy[:,0,:])\n",
    "        # norm[ norm[:,2]<0, :] *= -1   # Don't use ! \n",
    "        norm = norm / ( np.reshape(np.linalg.norm(norm, axis=1), (-1,1)) * np.ones((1,3)))\n",
    "        # DOn't smooth norm \n",
    "\n",
    "        if ref_node_data is None:            \n",
    "            return pd.DataFrame({\n",
    "                'time': time,\n",
    "                'markers': markers,\n",
    "                'center': list(center), \n",
    "                'norm': list(norm)\n",
    "                })    \n",
    "\n",
    "        ############################\n",
    "        #### Relative Movements ####\n",
    "\n",
    "        # Reader center/norm     \n",
    "        N = 10\n",
    "        ref_center = np.tile( np.mean(ref_node_data.center.loc[:N], axis=0), (len(ref_node_data),1) )\n",
    "        ref_norm = np.tile( np.mean(ref_node_data.norm.loc[:N], axis=0), (len(ref_node_data),1) )            \n",
    "        \n",
    "        distance_vec = ref_center - center                                                                  # Distance (vector)        \n",
    "        distance = np.linalg.norm( distance_vec, axis=1)                                                    # Distance\n",
    "        lat_misalignment = np.sqrt(distance**2 - np.sum(np.multiply( distance_vec, ref_norm), axis=1)**2)   # Lateral Misalignment                   \n",
    "        ang_misalignment = np.arcsin( np.linalg.norm(np.cross(ref_norm, norm), axis=1) )*180/np.pi          # Angular Misalignment\n",
    "\n",
    "        # Smoothing (smooth these params after all calculation)               \n",
    "        distance = signal.savgol_filter( distance, window_length=window_length, polyorder=1, axis=0)                        \n",
    "        lat_misalignment = signal.savgol_filter( lat_misalignment, window_length=window_length, polyorder=1, axis=0)        \n",
    "        ang_misalignment = signal.savgol_filter( ang_misalignment, window_length=window_length, polyorder=1, axis=0)  \n",
    "\n",
    "        if full_motion_data:\n",
    "            return pd.DataFrame({\n",
    "                'time': time,\n",
    "                'markers': markers,\n",
    "                'center': list(center), \n",
    "                'norm': list(norm),\n",
    "                'distance': list(distance),\n",
    "                'lat_misalignment': list(lat_misalignment),\n",
    "                'ang_misalignment': list(ang_misalignment)\n",
    "                })       \n",
    "        else:\n",
    "            return pd.DataFrame({\n",
    "                'time': time,\n",
    "                'distance': list(distance),\n",
    "                'lat_misalignment': list(lat_misalignment),\n",
    "                'ang_misalignment': list(ang_misalignment)\n",
    "                })                      \n",
    "    ################################################################################################################################################\n",
    "    def get_rssi(self, dataset_name, file_name, window_length=11):\n",
    "        # Load data \n",
    "        rfid_file_path = get_rfid_file_path(dataset_name, file_name)       \n",
    "        raw_df = pd.read_csv(\n",
    "            rfid_file_path,                                                     # relative python path to subdirectory\n",
    "            delimiter  = ';',                                                   # Tab-separated value file.\n",
    "            usecols = ['IDD', 'Time', 'Ant/RSSI'],                              # Only load the three columns specified.\n",
    "            parse_dates = ['Time'] )                                            # Intepret the birth_date column as a date      \n",
    "        raw_df = raw_df.loc[ raw_df['IDD'] == self.IDD, :]\n",
    "\n",
    "        # Time\n",
    "        date_time = pd.to_datetime( raw_df['Time'] , format=datime_format)\n",
    "        time = [ np.round( (datetime.combine(date.min, t.time())-datetime.min).total_seconds(), 2) for t in date_time]\n",
    "        \n",
    "        # RSSI\n",
    "        # rssi_df = pd.DataFrame({ 'rssi': raw_df['Ant/RSSI'].str.replace('Ant.No 1 - RSSI: ', '').astype(int) })\n",
    "        rssi_df = raw_df['Ant/RSSI'].str.replace('Ant.No 1 - RSSI: ', '').astype(float) \n",
    "        rssi_df = rssi_df.rolling(window_length, axis=0).median()   # Smoothing\n",
    "        rssi_df = rssi_df.ffill(axis=0).bfill(axis=0)               # Gap Filling\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'time':time,\n",
    "            'rssi':rssi_df.tolist() \n",
    "            })\n",
    "    ################################################################################################################################################\n",
    "    def get_vind(self, dataset_name, file_name, window_length=11):\n",
    "        # Load data \n",
    "        arduino_file_path = get_arduino_file_path(dataset_name, file_name)               \n",
    "        raw_df = pd.read_csv(arduino_file_path)\n",
    "        raw_df = raw_df.loc[ raw_df['port'] == self.port, :]\n",
    "\n",
    "        # Time\n",
    "        date_time = pd.to_datetime( raw_df['time'] , format=datime_format)\n",
    "        time = [ np.round( (datetime.combine(date.min, t.time())-datetime.min).total_seconds(), 2) for t in date_time]\n",
    "        \n",
    "        # RSSI\n",
    "        # rssi_df = pd.DataFrame({ 'rssi': raw_df['Ant/RSSI'].str.replace('Ant.No 1 - RSSI: ', '').astype(int) })\n",
    "        vind_df = raw_df['vind'].astype(float) \n",
    "        vind_df = vind_df.rolling(window_length, axis=0).median()   # Smoothing\n",
    "        vind_df = vind_df.ffill(axis=0).bfill(axis=0)               # Gap Filling\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'time':time,\n",
    "            'vind':vind_df.tolist() \n",
    "            })\n",
    "########################################################################################################################################################################################################################################################################################################\n",
    "class SYSTEM(object):\n",
    "    ################################################################################################################################################\n",
    "    def __init__(self, system_info = None):\n",
    "        self.reader = None\n",
    "        self.tags = list()\n",
    "\n",
    "        if system_info is not None:\n",
    "            \n",
    "            for idx in sys_info.index:                \n",
    "                node_info = sys_info.loc[idx, sys_info.columns!='type'].to_dict()                \n",
    "                for key,value in node_info.items():\n",
    "                    if value == 'None': node_info.update({key: None})\n",
    "                \n",
    "                node = NODE( **node_info )\n",
    "                if sys_info.loc[idx, 'type'] == 'tag': self.tags.append(node)\n",
    "                else: self.reader = node\n",
    "        return\n",
    "    ################################################################################################################################################\n",
    "    def add_reader(self, reader_markers_color):\n",
    "        self.reader = NODE( reader_markers_color )\n",
    "        return\n",
    "    ################################################################################################################################################\n",
    "    def add_tag(self, markers_color, IDD=None, port=None):\n",
    "        self.tags.append( NODE(markers_color, IDD=IDD, port=port) )   \n",
    "        return               \n",
    "    ################################################################################################################################################\n",
    "    def get_data(self, dataset_name, file_name, save=False, window_length=11):\n",
    "        reader_data = self.reader.get_data(dataset_name, file_name)  \n",
    "        data = pd.DataFrame({'time':reader_data.time})\n",
    "\n",
    "        for i, tag in enumerate(self.tags):\n",
    "            tag_data = tag.get_data(dataset_name, file_name, ref_node_data=reader_data)\n",
    "            tag_data = tag_data.add_suffix('_'+str(i)).rename({'time_'+str(i):'time'}, axis='columns')\n",
    "            data = data.merge( tag_data, on='time', how='outer', suffixes=('', '' ), sort=True )\n",
    "\n",
    "        data.interpolate(method='nearest', inplace=True)  \n",
    "        data.time -= data.time.loc[0]    \n",
    "        \n",
    "        # Save\n",
    "        if save:\n",
    "            dataset_file_path = get_dataset_file_path(dataset_name, file_name)\n",
    "            create_folder(dataset_file_path)\n",
    "            data.to_pickle( dataset_file_path)  \n",
    "            print(file_name, 'is saved.')\n",
    "\n",
    "        return data\n",
    "####################################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MATLAB data\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "dataset_name = 'dataset_07'    \n",
    "sys_info = get_sys_info(dataset_name)    \n",
    "sys = SYSTEM(system_info=sys_info)\n",
    "\n",
    "folder_path = '../' + dataset_name + '/' \n",
    "create_folder(folder_path + 'alaki.alaki')\n",
    "\n",
    "for n in range(30):\n",
    "    file_name = 'record_' + \"{0:0=2d}\".format(n)\n",
    "    data = sys.reader.get_data(dataset_name, file_name)  \n",
    "\n",
    "    for i, tag in enumerate(sys.tags):\n",
    "        tag_data = tag.get_data(dataset_name, file_name, ref_node_data=data, full_motion_data=True)\n",
    "        tag_data = tag_data.add_suffix('_'+str(i)).rename({'time_'+str(i):'time'}, axis='columns')\n",
    "        data = data.merge( tag_data, on='time', how='outer', suffixes=('', '' ), sort=True )\n",
    "\n",
    "    data.interpolate(method='nearest', inplace=True)  \n",
    "    data.time -= data.time.loc[0]    \n",
    "\n",
    "    sio.savemat(folder_path + file_name +'.mat', {name: col.values for name, col in data.items()}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset_name = 'dataset_00'\n",
    "\n",
    "# time_folder_path = main_directory + '/dataset/' + dataset_name + '/kinect/time'\n",
    "# markers_folder_path = main_directory + '/dataset/' + dataset_name + '/kinect/markers'\n",
    "\n",
    "# for n in range(30):\n",
    "#     file_name = 'record_' + \"{0:0=2d}\".format(n)\n",
    "    \n",
    "#     time_file_path = time_folder_path + '/' + file_name + '.txt'   \n",
    "#     with open(time_file_path , 'r') as f:  lines = f.read().splitlines() \n",
    "#     date_time = pd.to_datetime( lines , format=datime_format)\n",
    "#     time = pd.DataFrame({'time':[t.time() for t in date_time]})\n",
    "             \n",
    "#     locations_dict_ = dict()\n",
    "#     for color in ['red','blue','green']:\n",
    "#         markers_file_path = markers_folder_path + '/' + file_name + '_' + color +'.txt' \n",
    "#         locations = pd.read_csv( markers_file_path, delimiter=\"\\t\", header=None, dtype=np.float64).to_numpy()\n",
    "# #         locations_dict_.update({color: locations})\n",
    "#         locations_dict_.update({color: list(map(list,locations))})\n",
    "    \n",
    "#     locations_dict = defaultdict(list)  \n",
    "#     for l in range(len(time)):\n",
    "#         for color in ['red','blue','green']:\n",
    "#             locations_dict[color].append( locations_dict_[color][l] )                            \n",
    "\n",
    "#   # MArkers (time and locations)\n",
    "#     markers = pd.concat([time, pd.DataFrame(locations_dict)], axis=1)\n",
    "\n",
    "#     # Save \n",
    "#     markers_file_path = get_markers_file_path(dataset_name, file_name)\n",
    "#     create_folder(markers_file_path)\n",
    "#     markers.to_csv(markers_file_path, index=False)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}