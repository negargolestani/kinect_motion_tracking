{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################################################################################################\n",
    "class NODE(object):\n",
    "    ################################################################################################################################################\n",
    "    def __init__(self, markers_color, IDD=None, port=None):\n",
    "        self.markers_color = markers_color\n",
    "        self.IDD = IDD\n",
    "        self.port = port\n",
    "    ################################################################################################################################################\n",
    "    def get_data(self, dataset_name, file_name, ref_node=None, window_length=11, ref_node_data=None):        \n",
    "        data = self.get_motion(dataset_name, file_name, window_length=window_length, ref_node_data=ref_node_data)  \n",
    "\n",
    "        if self.IDD is not None: \n",
    "            rssi = self.get_rssi(dataset_name, file_name, window_length=window_length)\n",
    "            data = data.merge( rssi, on='time', how='outer', suffixes=('', ''), sort=True )\n",
    "\n",
    "        if self.port is not None: \n",
    "            vind = self.get_vind(dataset_name, file_name, window_length=window_length)\n",
    "            data = data.merge( vind, on='time', how='outer', suffixes=('', ''), sort=True )\n",
    "\n",
    "        return data\n",
    "    ################################################################################################################################################\n",
    "    def get_motion(self, dataset_name, file_name, window_length=11, ref_node_data=None):   \n",
    "        markers_file_path = get_markers_file_path(dataset_name, file_name)  \n",
    "        raw_df  = pd.read_csv(\n",
    "            markers_file_path,                                                  # relative python path to subdirectory\n",
    "            usecols = ['time', self.markers_color],                             # Only load the three columns specified.\n",
    "            parse_dates = ['time'] ) \n",
    "        \n",
    "\n",
    "        # Time\n",
    "        date_time = pd.to_datetime( raw_df['time'] , format=datime_format)\n",
    "        time = [ np.round( (datetime.combine(date.min, t.time())-datetime.min).total_seconds(), 2) for t in date_time]\n",
    "        \n",
    "        # Markers\n",
    "        markers = [list(map(float, l.replace(']','').replace('[','').replace('\\n','').split(\", \"))) for l in raw_df[self.markers_color].values]  \n",
    "        markers_npy = np.array(markers).reshape(len(time), -1, 3)\n",
    "        # DON'T Smooth markers. markers can be switched in array and smoothing causes error    \n",
    "\n",
    "        # Center    \n",
    "        center = np.mean(markers_npy, axis=1)         \n",
    "        center = np.nan_to_num(center)\n",
    "        center = signal.savgol_filter( center, window_length=window_length, polyorder=1, axis=0)     \n",
    "\n",
    "        # Norm\n",
    "        norm = np.cross( markers_npy[:,1,:] - markers_npy[:,0,:], markers_npy[:,2,:] - markers_npy[:,0,:])\n",
    "        # norm[ norm[:,2]<0, :] *= -1   # Don't use ! \n",
    "        norm = norm / ( np.reshape(np.linalg.norm(norm, axis=1), (-1,1)) * np.ones((1,3)))\n",
    "        # DOn't smooth norm \n",
    "\n",
    "        if ref_node_data is None:            \n",
    "            return pd.DataFrame({\n",
    "                'time': time,\n",
    "                'markers': markers,\n",
    "                'center': list(center), \n",
    "                'norm': list(norm)\n",
    "                })    \n",
    "\n",
    "        ############################\n",
    "        #### Relative Movements ####\n",
    "\n",
    "        # Reader center/norm     \n",
    "        N = 10\n",
    "        ref_center = np.tile( np.mean(ref_node_data.center.loc[:N], axis=0), (len(ref_node_data),1) )\n",
    "        ref_norm = np.tile( np.mean(ref_node_data.norm.loc[:N], axis=0), (len(ref_node_data),1) )            \n",
    "        \n",
    "        distance_vec = ref_center - center                                                                  # Distance (vector)        \n",
    "        distance = np.linalg.norm( distance_vec, axis=1)                                                    # Distance\n",
    "        lat_misalignment = np.sqrt(distance**2 - np.sum(np.multiply( distance_vec, ref_norm), axis=1)**2)   # Lateral Misalignment                   \n",
    "        ang_misalignment = np.arcsin( np.linalg.norm(np.cross(ref_norm, norm), axis=1) )*180/np.pi          # Angular Misalignment\n",
    "\n",
    "        # Smoothing (smooth these params after all calculation)               \n",
    "        distance = signal.savgol_filter( distance, window_length=window_length, polyorder=1, axis=0)                        \n",
    "        lat_misalignment = signal.savgol_filter( lat_misalignment, window_length=window_length, polyorder=1, axis=0)        \n",
    "        ang_misalignment = signal.savgol_filter( ang_misalignment, window_length=window_length, polyorder=1, axis=0)  \n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'time': time,\n",
    "            'markers': markers,\n",
    "            'center': list(center), \n",
    "            'norm': list(norm),\n",
    "            'distance': list(distance),\n",
    "            'lat_misalignment': list(lat_misalignment),\n",
    "            'ang_misalignment': list(ang_misalignment)\n",
    "            })                 \n",
    "    ################################################################################################################################################\n",
    "    def get_rssi(self, dataset_name, file_name, window_length=11):\n",
    "        # Load data \n",
    "        rfid_file_path = get_rfid_file_path(dataset_name, file_name)       \n",
    "        raw_df = pd.read_csv(\n",
    "            rfid_file_path,                                                     # relative python path to subdirectory\n",
    "            delimiter  = ';',                                                   # Tab-separated value file.\n",
    "            usecols = ['IDD', 'Time', 'Ant/RSSI'],                              # Only load the three columns specified.\n",
    "            parse_dates = ['Time'] )                                            # Intepret the birth_date column as a date      \n",
    "\n",
    "        # self.rssi.loc[ self.rssi.IDD != self.IDD,'rssi'] = np.nan\n",
    "        raw_df = raw_df.loc[ raw_df['IDD'] == self.IDD, :]\n",
    "\n",
    "        # Time\n",
    "        date_time = pd.to_datetime( raw_df['Time'] , format=datime_format)\n",
    "        time = [ np.round( (datetime.combine(date.min, t.time())-datetime.min).total_seconds(), 2) for t in date_time]\n",
    "        \n",
    "        # RSSI\n",
    "        # rssi_df = pd.DataFrame({ 'rssi': raw_df['Ant/RSSI'].str.replace('Ant.No 1 - RSSI: ', '').astype(int) })\n",
    "        rssi_df = raw_df['Ant/RSSI'].str.replace('Ant.No 1 - RSSI: ', '').astype(int) \n",
    "        rssi_df = rssi_df.rolling(window_length, axis=0).median()   # Smoothing\n",
    "        rssi_df = rssi_df.ffill(axis=0).bfill(axis=0)               # Gap Filling\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'time':time,\n",
    "            'rssi':rssi_df.tolist() \n",
    "            })\n",
    "    ################################################################################################################################################\n",
    "    def get_vind(self, dataset_name, file_name, window_length=11):\n",
    "        # Load data \n",
    "        arduino_file_path = get_arduino_file_path(dataset_name, file_name)               \n",
    "        raw_df = pd.read_csv(arduino_file_path)\n",
    "\n",
    "        # Time\n",
    "        date_time = pd.to_datetime( raw_df['time'] , format=datime_format)\n",
    "        time = [ np.round( (datetime.combine(date.min, t.time())-datetime.min).total_seconds(), 2) for t in date_time]\n",
    "\n",
    "        # V_induced (Vind)\n",
    "        vind = raw_df[self.port]\n",
    "        vind = vind.rolling(window_length, axis=0).median()   # Smoothing\n",
    "        vind = vind.ffill(axis=0).bfill(axis=0)               # Gap Filling\n",
    "         \n",
    "        return pd.DataFrame({\n",
    "            'time':time,\n",
    "            'vind':vind.tolist()\n",
    "        })\n",
    "########################################################################################################################################################################################################################################################################################################\n",
    "class SYSTEM(object):\n",
    "    ################################################################################################################################################\n",
    "    def __init__(self, system_info = None):\n",
    "        self.reader = None\n",
    "        self.tags = list()\n",
    "\n",
    "        if system_info is not None:\n",
    "            system_info_ = system_info.copy()\n",
    "            reader_markers_color = system_info_.pop('reader')\n",
    "            self.add_reader(reader_markers_color)\n",
    "            for IDD,markers_color in system_info_.items(): self.add_tag(markers_color, IDD)\n",
    "        return\n",
    "    ################################################################################################################################################\n",
    "    def add_reader(self, reader_markers_color):\n",
    "        self.reader = NODE( reader_markers_color )\n",
    "        return\n",
    "    ################################################################################################################################################\n",
    "    def add_tag(self, markers_color, IDD=None, port=None):\n",
    "        self.tags.append( NODE(markers_color, IDD=IDD, port=port) )   \n",
    "        return               \n",
    "    ################################################################################################################################################\n",
    "    def get_data(self, dataset_name, file_name, save=False, window_length=11):\n",
    "        reader_data = self.reader.get_data(dataset_name, file_name)  \n",
    "        data = pd.DataFrame({'time':reader_data.time})\n",
    "\n",
    "        for i, tag in enumerate(self.tags):\n",
    "            tag_data = tag.get_data(dataset_name, file_name, ref_node_data=reader_data)\n",
    "            tag_data = tag_data.add_suffix('_'+str(i)).rename({'time_'+str(i):'time'}, axis='columns')\n",
    "            data = data.merge( tag_data, on='time', how='outer', suffixes=('', '' ), sort=True )\n",
    "\n",
    "    \n",
    "        # Select specific time samples \n",
    "        target_time = data.time[ np.where(np.any( ~np.isnan(data.filter(regex='rssi', axis=1)), axis=1))[0] ]   # time samples that at least one rssi is not Nan\n",
    "        data = data.interpolate(method='nearest')        \n",
    "        data.loc[:, data.columns!='time'] = data.loc[:, data.columns!='time'].rolling(window_length, axis=0).mean().fillna(method='ffill', axis=0).bfill(axis=0)      \n",
    "        data = data.merge( pd.DataFrame({'time':target_time}), on='time', how='inner', suffixes=('', '' ), sort=True )\n",
    "     \n",
    "        # Save\n",
    "        if save:\n",
    "            dataset_file_path = get_dataset_file_path(dataset_name, file_name)\n",
    "            create_folder(dataset_file_path)\n",
    "            data.to_pickle( dataset_file_path)  \n",
    "            print(file_name, 'is saved.')\n",
    "\n",
    "        return data\n",
    "####################################################################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'dataset_05'   \n",
    "matfolder_file_path = './matdata/'\n",
    "\n",
    "for n in range(1):\n",
    "    file_name = 'record_' + \"{0:0=2d}\".format(n)\n",
    "    dataset_file_path = get_dataset_file_path(dataset_name, file_name)\n",
    "    data = pd.read_pickle(dataset_file_path)\n",
    "\n",
    "    # sio.savemat( matfolder_file_path + file_name +'.mat', {name: col.values for name, col in data.items()}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-08-10 14:37:31.500321\n2020-08-10 14:37:34.500321\n"
    }
   ],
   "source": [
    "\n",
    "x = datetime.now() \n",
    "print(x)\n",
    "x += timedelta(seconds=10)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'tag'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'markers_color': 'red', 'IDD': None, 'port': None}"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "sio.savemat(os.path.join(destination_folder_path,'meta.mat'), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset_name = 'dataset_00'\n",
    "\n",
    "# time_folder_path = main_directory + '/dataset/' + dataset_name + '/kinect/time'\n",
    "# markers_folder_path = main_directory + '/dataset/' + dataset_name + '/kinect/markers'\n",
    "\n",
    "# for n in range(30):\n",
    "#     file_name = 'record_' + \"{0:0=2d}\".format(n)\n",
    "    \n",
    "#     time_file_path = time_folder_path + '/' + file_name + '.txt'   \n",
    "#     with open(time_file_path , 'r') as f:  lines = f.read().splitlines() \n",
    "#     date_time = pd.to_datetime( lines , format=datime_format)\n",
    "#     time = pd.DataFrame({'time':[t.time() for t in date_time]})\n",
    "             \n",
    "#     locations_dict_ = dict()\n",
    "#     for color in ['red','blue','green']:\n",
    "#         markers_file_path = markers_folder_path + '/' + file_name + '_' + color +'.txt' \n",
    "#         locations = pd.read_csv( markers_file_path, delimiter=\"\\t\", header=None, dtype=np.float64).to_numpy()\n",
    "# #         locations_dict_.update({color: locations})\n",
    "#         locations_dict_.update({color: list(map(list,locations))})\n",
    "    \n",
    "#     locations_dict = defaultdict(list)  \n",
    "#     for l in range(len(time)):\n",
    "#         for color in ['red','blue','green']:\n",
    "#             locations_dict[color].append( locations_dict_[color][l] )                            \n",
    "\n",
    "#   # MArkers (time and locations)\n",
    "#     markers = pd.concat([time, pd.DataFrame(locations_dict)], axis=1)\n",
    "\n",
    "#     # Save \n",
    "#     markers_file_path = get_markers_file_path(dataset_name, file_name)\n",
    "#     create_folder(markers_file_path)\n",
    "#     markers.to_csv(markers_file_path, index=False)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}